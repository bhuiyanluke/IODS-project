---
title: "Chapter2_regression analysis"
author: "Rabbil Bhuiyan"
date: "11 November 2018"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r "chapter1.Rmd"}
# dimension of the data
dim(lrn14)

#structure of the data
str(lrn14)

#Output of the codes
#183 observations and 60 variables were found

# access the dplyr library
library(dplyr)

# Analysis dataset
keep_columns <- c("gender","Age","attitude", "deep", "stra", "surf", "Points")

# select the 'keep_columns' to create a new dataset named learning2014
learning2014 <- select(lrn14, one_of(keep_columns))

# see the structure of the new dataset
str(learning2014, points = 0)


# excluding of observations
library(dplyr)

# select male students
male_students <- filter(learning2014, gender == "M")

# select rows where Points is greater than zero
learning2014 <- filter(learning2014, Points > 0)

str(learning2014, Points > 0)

Scale of variables to original scale(# Access the dplyr library
  library(dplyr)
# questions related to deep, surface and strategic learning
  deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
  surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
  strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
  
# select the columns related to deep learning and create column 'deep' by averaging
  deep_columns <- select(lrn14, one_of(deep_questions))
  lrn14$deep <- rowMeans(deep_columns)
  
# select the columns related to surface learning and create column 'surf' by averaging
  surface_columns <- select(lrn14, one_of(surface_questions))
  lrn14$surf <- rowMeans(surface_columns)
  
# select the columns related to strategic learning and create column 'stra' by averaging
  strategic_columns <- select(lrn14, one_of(strategic_questions))
  lrn14$stra <- rowMeans(strategic_columns)
  

```{r "chapter2.Rmd"}
# read the data
student2014 <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", sep = ",", header=TRUE)

# dimension of the data
dim(student2014)

#structure of the data
str(student2014)
```
# description of the data:
#The data has 166 observation and 7 variables namely gender, age, attitude, deep, stra, surf and points.

#summary of the data

```{r cars}
summary(student2014)
summary(student2014$age)
#Acess the ggplot2 library
library(ggplot2)
# initialize plot with data and aesthetic mapping
p1 <- ggplot(student2014, aes(x = attitude, y = points, col = gender))

# define the visualization type (points)
p2 <- p1 + geom_point()

# draw the plot
p2

# add a regression line
p3 <- p2 + geom_smooth(method = "lm")

# add a main title and draw the plot
p4 <- p3 + ggtitle("Student's attitude versus exam points")
p4
# description of the output: the anlayis shows the descriptives of each variables.Then the plot of student attitude vs exam points for both male and female
```

## Creation of Plots


```{r pressure, echo=FALSE}
plot(student2014)
# output of the plot: this graph tells about the plots for all the variables; how each varables are corelated with others
```
```{r}
# a scatter plot of points versus attitude
library(ggplot2)


# fit a linear model
my_model <- lm(points ~ attitude + stra + surf, data = student2014)

# print out a summary of the model
summary(my_model)
#output: none of the varible estimates were significant. then we removed one variable and check the significance level

# fit a linear model with removing one variable
my_model1 <- lm(points ~ attitude + stra, data = student2014)

# print out a summary of the model
summary(my_model1)

# fit a linear model removing another variable
my_mode2 <- lm(points ~ attitude + surf, data = student2014)

# print out a summary of the model
summary(my_mode2)

#Output: In all cases the attitude variable was signficanlty correlated with the dependent variable points


```
```{r}
#regression model validation

# regression model with multiple explanatory variables
my_model1 <- lm(points ~ attitude + stra, data = student2014)

# draw diagnostic plots 
par(mfrow = c(2,2))
plot(my_model1, which = c(1,2,5))
#description of the model validation
#From the resifual vs fitted validation model we see no clear pattern of the data- random distribution of data and it means the validation of quite good and thus the model parameter estimates. In the second  method, the q-q plot shows that the values are almost distributed along the line which mean good fit of the model. In the third validation model, we also see no outlier and thus the liverage is not high which means good fit of the model.
```




Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
