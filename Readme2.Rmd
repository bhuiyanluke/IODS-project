---
title: "IODS project"
author: "Rabbil Bhuiyan"
date: "31 October 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r child = "chapter1.Rmd"}
The course is intended to learn different tools for analyzing data, particularly by using rstudio. All the tasks completed using R will be linked and stored in Github account. The course also uses Datacamp for excercising the R tools to learn it.
https://github.com/bhuiyanluke/IODS-project/
  ```{r child = "chapter2.Rmd"}
- This week, from the begining of the lecture, I have learned using the Github and linked it to the rstudio. I had prior knowledge about rstudio but not in details. Linking the Github with rstudio was exciting. How to store the saved work in Github was very useful to me. The porcedure for storing the work in Github as follows:
-I opened the Github account
-Then fork it to the course repisotory as the instruction of the lecture
-Opened the Github desktop account
-And also cloned this with the course repisotory
-Opened the taks in rstudio and saved after editing
-Then commited to master in Github desktop
-Then I can see the changes in Github repisotory
Finally I stored all the work done in Gitbub and other people can also see my work
  
```
```{r child = "chapter3.Rmd"
```{r}
```

Reading data file into R 
url <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets"

# web address for math class data
url_math <- paste(url, "student-mat.csv", sep = "/")

# print out the address
url_math

# read the math class questionaire data into memory
math <- read.table(url_math, sep = ";" , header=TRUE)

# web address for portuguese class data
url_por <- paste(url, "student-por.csv", sep ="/")

# print out the address
url_por

# read the portuguese class questionaire data into memory
por <- read.table(url_por, sep = ";", header = TRUE)
# dimension of the data
dim(math)
dim(por)
# description of the variables: the both data set has 33 vairables.

# access the dplyr library
library(dplyr)


# common columns to use as identifiers
join_by <- c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet")

# join the two datasets by the selected identifiers
math_por <- inner_join(math, por, by = join_by, suffix = c(".math", ".por"))

# Strucure and dimension of the joined data set
str(math_por)
dim(math_por)

   

}


```
 

```{r}
# access the MASS package
library(MASS)

# load the data
data("Boston")

# explore the dataset
str(Boston)
summary(Boston)

#Explanation of the dataset
# The data set is about the housing values of suburb of Boston. It has 506 observations and 14 variables.There is the pairwise comparsion between the variables of the dataset.

# plot matrix of the variables

plot(Boston)
```
```{r}
# MASS, corrplot, tidyverse and Boston dataset are available
library(MASS)
library(corrplot)
library(tidyverse)
data("Boston")

# calculate the correlation matrix and round it
cor_matrix<-cor(Boston)  %>% round(digit=2)

# print the correlation matrix
cor_matrix
# Description of the variable correlations: how the variables are corelated to each other are displayed in tabular form with two rounded digit. 

# visualize the correlation matrix
corrplot(cor_matrix, method="circle", type="upper",cl.pos="b", tl.pos="d",tl.cex= 0.6)
#Descriptin of the data: The variable owner-occupied homes are highly and positvely corelated and crime rate by town is negatrively highly corelated.
```
```

```{r}
# MASS and Boston dataset are available

# center and standardize variables
boston_scaled <- scale(Boston)

# summaries of the scaled variables
summary(boston_scaled)

# class of the boston_scaled object
class(boston_scaled)

# change the object to data frame
boston_scaled  <- as.data.frame(boston_scaled)
```

```{r}
# MASS, Boston and boston_scaled are available

# summary of the scaled crime rate
summary(boston_scaled$crim)

# create a quantile vector of crim and print it
bins <- quantile(boston_scaled$crim)
bins

# create a categorical variable 'crime'
crime <- cut(boston_scaled$crim, breaks = bins, include.lowest = TRUE, labels = c("low", "med_low", "med_high", "high"))

# look at the table of the new factor crime
table(crime)

# remove original crim from the dataset
boston_scaled <- dplyr::select(boston_scaled, -crim)

# add the new categorical value to scaled data
boston_scaled <- data.frame(boston_scaled, crime)

```

```{r}
# boston_scaled is available

# number of rows in the Boston dataset 
n <- nrow(boston_scaled)

# choose randomly 80% of the rows
ind <- sample(n,  size = n * 0.8)

# create train set
train <- boston_scaled[ind,]

# create test set 
test <- boston_scaled[-ind,]

# save the correct classes from test data
correct_classes <- test$crime

# remove the crime variable from test data
test <- dplyr::select(test, -crime)

```

```{r}
# MASS and train are available

# linear discriminant analysis
lda.fit <- lda(crime ~ ., data = train)

# print the lda.fit object
lda.fit

# the function for lda biplot arrows
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "orange", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}

# target classes as numeric
classes <- as.numeric(train$crime)

# plot the lda results
plot(lda.fit, dimen = 2, col = classes, pch = classes)
lda.arrows(lda.fit, myscale = 1)

```

```{r}
# lda.fit, correct_classes and test are available

# predict classes with test data
lda.pred <- predict(lda.fit, newdata = test)

# cross tabulate the results
table(correct = correct_classes, predicted = lda.pred$class)
```
```{r}
# load MASS and Boston
library(MASS)
data('Boston')

# euclidean distance matrix
dist_eu <- dist(Boston)

# look at the summary of the distances
summary(dist_eu)

# manhattan distance matrix
dist_man <- dist(Boston, method= 'manhattan')

# look at the summary of the distances

summary(dist_man)
```

```{r}
# Boston dataset is available

# k-means clustering
km <-kmeans(Boston, centers = 3)

# plot the Boston dataset with clusters
pairs(Boston, col = km$cluster)
```
```{r}
# MASS, ggplot2 and Boston dataset are available
set.seed(123)

# determine the number of clusters
k_max <- 10

# calculate the total within sum of squares
twcss <- sapply(1:k_max, function(k){kmeans(Boston, k)$tot.withinss})

# visualize the results
qplot(x = 1:k_max, y = twcss, geom = 'line')

# k-means clustering
km <-kmeans(Boston, centers = 2)

# plot the Boston dataset with clusters
pairs(Boston, col = km$cluster)
```




